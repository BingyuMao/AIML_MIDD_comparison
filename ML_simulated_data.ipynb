{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dbbd315-0dbf-4217-adf2-30796496a7db",
   "metadata": {},
   "source": [
    "### Get the simulated data from NONMEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b02dd-ae4a-4284-afde-69685664b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# Basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, root_mean_squared_error\n",
    "#models\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25efb2b-72a9-4e66-b992-e2b46ab047bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV data file from NONMEM\n",
    "df = pd.read_csv('../data_from_NONMEM.csv')\n",
    "df = df.rename(columns={'ID': 'CID','AMT': 'Dose', 'DV': 'Concn'})\n",
    "# Select the first 500 patients\n",
    "df = df[df['CID'].between(1, 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059a879e-15dc-4277-8162-b3adc321f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns into float first and handle missing values\n",
    "# The 'errors'='coerce' argument will replace non-convertible values with NaN. \n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df[col] = df[col].fillna(0) #filling missing values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640d71d5-b691-49cd-8235-c86822200eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the specific time points you want to keep\n",
    "time_points = [0, 1, 2, 4, 6, 8, 12, 18, 24, 36, 48, 72, 96, 120, 144]\n",
    "\n",
    "# Filter the dataframe to only include rows where the 'TIME' column matches one of the specified time points\n",
    "data = df[df['TIME'].isin(time_points)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf5c1c-3609-496c-a9b1-a5828df0b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the filtered dataset to a new CSV file\n",
    "data.to_csv('data_ready.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d730284b-9fbd-4bca-b405-085622c9ddbd",
   "metadata": {},
   "source": [
    "### Data preprocess for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a1205-7a14-4607-9b6e-a479e3b3afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some numbers\n",
    "PT = 100 #sample size\n",
    "SEED = 12 #random seed to make the results reproducible\n",
    "METRIC = 'neg_root_mean_squared_error' #the main metric we will use for grid search and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29ad8f-2b35-4d5a-9ece-90932a64b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('data_ready.csv')\n",
    "# Select the first some patients for the subset\n",
    "df = df[df['CID'].between(1, PT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a1262-4472-4081-ba07-0d698abf253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values by CID and TIME to ensure correct alignment\n",
    "df.sort_values(by=['CID', 'TIME'], inplace=True)\n",
    "\n",
    "# Convert \"TIME\" to time difference within each patient\n",
    "df['Time_diff'] = df.groupby('CID')['TIME'].diff().fillna(0)\n",
    "\n",
    "# Shift the Concn column to create the target variable: next time point's concentration\n",
    "# We group by 'CID' to make sure the shift is done within each patient\n",
    "df['Next_Concn'] = df.groupby('CID')['Concn'].shift(-1)\n",
    "\n",
    "# Drop the last observation of each patient because it now has a NaN target\n",
    "df.dropna(subset=['Next_Concn'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5b748-6cd8-49ff-8f55-aa4607f04261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique patients (CIDs)\n",
    "unique_cids = df['CID'].unique()\n",
    "# Randomly shuffle the CIDs\n",
    "random.shuffle(unique_cids)\n",
    "\n",
    "# Split the CIDs into training and testing\n",
    "train_size = int(0.7 * len(unique_cids))\n",
    "train_cids = unique_cids[:train_size]\n",
    "test_cids = unique_cids[train_size:]\n",
    "\n",
    "# Filter the data based on the selected CIDs for training and testing\n",
    "train_data = df[df['CID'].isin(train_cids)]\n",
    "test_data = df[df['CID'].isin(test_cids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395dcce-b3bc-44be-8b6a-71f0d26cc4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define normalization function\n",
    "def normalize_column(column, scale_range):\n",
    "    min_val = column.min()\n",
    "    max_val = column.max()\n",
    "    normalized = (column - min_val) / (max_val - min_val) * (scale_range[1] - scale_range[0]) + scale_range[0]\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96469ce-1f8a-4228-a37a-ac2fc22e160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization to each column\n",
    "train_data['td'] = normalize_column(train_data['Time_diff'], (train_data['Dose'].min(), train_data['Dose'].max()))\n",
    "train_data['con'] = normalize_column(train_data['Concn'], (train_data['Dose'].min(), train_data['Dose'].max()))\n",
    "train_data['next'] = normalize_column(train_data['Next_Concn'], (train_data['Dose'].min(), train_data['Dose'].max()))\n",
    "\n",
    "test_data['td'] = normalize_column(test_data['Time_diff'], (test_data['Dose'].min(), test_data['Dose'].max()))\n",
    "test_data['con'] = normalize_column(test_data['Concn'], (test_data['Dose'].min(), test_data['Dose'].max()))\n",
    "test_data['next'] = normalize_column(test_data['Next_Concn'], (test_data['Dose'].min(), test_data['Dose'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c4691e-cb4a-4c6b-9f3f-ad7956c21065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting features and target for training and testing\n",
    "X_train = train_data[['td', 'Dose', 'con']]\n",
    "y_train = train_data['next']\n",
    "X_test = test_data[['td', 'Dose', 'con']]\n",
    "y_test = test_data['next']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110f368-8bfa-44c4-a239-9f04badbef50",
   "metadata": {},
   "source": [
    "### Run ML methods to get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab47d0a-d3fd-4fb4-99c2-2c0a93f8c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ML models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': Lasso(),\n",
    "    'XGBoost': xgb.XGBRegressor(objective='reg:squarederror', seed=SEED)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27b934-1b7f-4981-bccf-0d70eb561090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search to find the best hyperparameter set\n",
    "param_grids = {\n",
    "    'Linear Regression': {},\n",
    "    'Lasso': {'alpha': [0.01, 0.1, 1]},\n",
    "    'XGBoost': {'n_estimators': [50, 100, 300], 'max_depth': [3, 5, 10], 'learning_rate': [0.05, 0.1, 0.3]}\n",
    "}\n",
    "\n",
    "best_estimators = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Grid search for {name}\")\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=10, scoring=METRIC, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_estimators[name] = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e7367-9921-4bc0-93bc-f47fabf644db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reverse normalization function\n",
    "def reverse_normalize_column(column, original_column, scale_range=(df['Dose'].min(), df['Dose'].max())):\n",
    "    min_val = original_column.min()\n",
    "    max_val = original_column.max()\n",
    "    reversed_values = column * (max_val - min_val) / (scale_range[1] - scale_range[0]) + min_val\n",
    "    return reversed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f52f6d-5729-475d-8a61-37ec4c701975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models with best hyperparameters and evaluate\n",
    "metrics = {}\n",
    "preds = {}\n",
    "\n",
    "for name, model in best_estimators.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    pred_real = reverse_normalize_column(pred, df['Next_Concn'])\n",
    "    preds[name] = pred_real\n",
    "      \n",
    "    metrics[name] = {\n",
    "        'RMSE': root_mean_squared_error(y_test, pred),\n",
    "        'MAE': mean_absolute_error(y_test, pred),\n",
    "        'R^2': r2_score(y_test, pred)\n",
    "    }\n",
    "    print(f\"Evaluation for {name}: RMSE={metrics[name]['RMSE']:.4f}, MAE={metrics[name]['MAE']:.4f}, R^2={metrics[name]['R^2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda4484-a965-49b9-a315-198581f2fce5",
   "metadata": {},
   "source": [
    "### Get AUCs for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e3464-121a-43d7-aa89-00b12ef5867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(preds)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50219ab-702a-43d6-bb71-e402cd4c40e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the indices of both dataframes\n",
    "test_data_reset = test_data.reset_index(drop=True)\n",
    "pred_df_reset = pred_df.reset_index(drop=True)\n",
    "# Concatenate the dataframes along axis 1\n",
    "res = pd.concat([test_data_reset, pred_df_reset], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1a07b-8a1e-41c1-8456-227765d33014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of predicted concentration columns\n",
    "predicted_columns = ['Linear Regression', 'Lasso', 'XGBoost']\n",
    "\n",
    "# Initialize a dictionary to store the AUCs for each model including the real concentration\n",
    "auc_results = {'Real': []}\n",
    "for col in predicted_columns:\n",
    "    auc_results[col] = []\n",
    "\n",
    "# Iterate over each patient\n",
    "for patient_id in res['CID'].unique():\n",
    "    # Filter the data for the selected patient\n",
    "    patient_data = res[res['CID'] == patient_id]\n",
    "\n",
    "    # Extract Time and Concn columns for the real concentration curve\n",
    "    time = patient_data['TIME']\n",
    "    real_concn = patient_data['Concn']\n",
    "\n",
    "    # Calculate AUC for the real concentration curve and store it\n",
    "    auc_real = np.trapz(real_concn, time)\n",
    "    auc_results['Real'].append(auc_real)\n",
    "\n",
    "    # Calculate AUC for each predicted model and store it\n",
    "    for col in predicted_columns:\n",
    "        auc_pred = np.trapz(patient_data[col], time)\n",
    "        auc_results[col].append(auc_pred)\n",
    "\n",
    "# Calculate the average AUC and standard deviation for each model\n",
    "results = []\n",
    "for model, aucs in auc_results.items():\n",
    "    avg_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "    formatted_result = f\"Avg. AUC(std) for {model}: {avg_auc:.2f} ({std_auc:.2f})\"\n",
    "    results.append(formatted_result)\n",
    "\n",
    "# Print the formatted results\n",
    "for result in results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
